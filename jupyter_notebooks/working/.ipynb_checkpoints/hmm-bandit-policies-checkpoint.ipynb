{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "username = getpass.getuser()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('/Users/{:}/GitHub/mouse_bandit/data_preprocessing_code'.format(username))\n",
    "sys.path.append('/Users/{:}/GitHub/mouse_bandit'.format(username))\n",
    "import support_functions as sf\n",
    "\n",
    "sys.path.append('/Users/{:}/GitHub/mouse_bandit/jupyter_notebooks/helper_functions'.format(username))\n",
    "import bandit_modeling as bm\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markov process is one in which the future state of the system does not depend on more (history) than the current state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function inputs: DATA, EMISSION_PROB, TRANSITION_PROB=0.02, STRATEGY, N_PREV_TRIALS\n",
    "def hmm_predict(data, emission_prob, transition_prob=0.02, strategy='greedy', n_prev_trials=10):\n",
    "    \n",
    "    '''\n",
    "    Inputs:\n",
    "        data = pandas dataframe containing port and reward features\n",
    "        emission_prob = reward probability observed by the agent\n",
    "        transition_prob = probability of transitioning between markovian states\n",
    "        strategy = 'greedy,' 'thompson,' 'eps_greedy'\n",
    "        n_prev_trials = int 1 to 10, how many previous trials are used to calculate belief state\n",
    "    '''\n",
    "    \n",
    "    # latent state z (0 left, 1 right)\n",
    "    # action a (0 left, 1 right)\n",
    "    # reward r (0 no reward, 1 reward)\n",
    "    # transition_prob (0 to 1)\n",
    "\n",
    "    # emission probabilities (observed probabilities of reward)\n",
    "    p = emission_prob # probability of reward for correct side\n",
    "    q = 1-p # probability of reward for incorrect side\n",
    "    s = 1-transition_prob # probability of remaining in same state\n",
    "\n",
    "    # transition matrix T[i,j] = p(i->j)\n",
    "    T = np.array([[s, transition_prob],\n",
    "                  [transition_prob, s]])\n",
    "\n",
    "    # observation array O\n",
    "    # O[r,z,a] = Pr(reward=r | state=z, action=a)\n",
    "    O = np.zeros((2,2,2)) # each component has two conditions 0,1\n",
    "    \n",
    "    # right choice = 0, no reward = 0, right state = 0\n",
    "    O[:,:,0] = np.array([[1-p, 1-q],[p,q]]) \n",
    "    O[:,:,1] = np.array([[1-q, 1-p],[q,p]])\n",
    "\n",
    "    # split data into train and test sets (ultimately using same seeds as with LR?)\n",
    "\n",
    "    n_trials = data.shape[0]\n",
    "\n",
    "    #include n_prev_trials past choice and reward values (this is most convenient given the current data structure)\n",
    "    port_features = []\n",
    "    reward_features = []\n",
    "    for col in data:\n",
    "        if '_Port' in col:\n",
    "            port_features.append(col)\n",
    "        elif '_Reward' in col:\n",
    "            reward_features.append(col)\n",
    "\n",
    "    y_predict = np.zeros(n_trials)\n",
    "    beliefs = np.zeros(n_trials)\n",
    "\n",
    "    for trial in range(n_trials):\n",
    "        curr_trial = data.iloc[trial]\n",
    "        actions = curr_trial[port_features].values.astype('int')\n",
    "        rewards = curr_trial[reward_features].values.astype('int')\n",
    "        beliefs_curr = np.nan*np.ones((n_prev_trials+1,2))\n",
    "        beliefs_curr[0] = [0.5,0.5] # initial belief is equal for each port\n",
    "\n",
    "        for i in range(n_prev_trials):\n",
    "\n",
    "            assert np.allclose(beliefs_curr[i].sum(), 1.0), \"Beliefs must sum to one!\"\n",
    "\n",
    "            belief_temp = O[rewards[i],:,actions[i]] * beliefs_curr[i]\n",
    "\n",
    "            beliefs_curr[i+1] = T.dot(belief_temp) # take dot product of transition matrix and previous belief\n",
    "\n",
    "            beliefs_curr[i+1] /= beliefs_curr[i+1].sum()\n",
    "        \n",
    "        if strategy == 'greedy':\n",
    "            y_predict[trial] = np.where(beliefs_curr[-1] == beliefs_curr[-1].max())[0][0] \n",
    "            \n",
    "        elif strategy == 'thompson':\n",
    "            y_predict[trial] = np.random.choice(2,p=beliefs_curr[-1])\n",
    "            #y_predict[trial] = np.random.choice(2,p=[p,q])\n",
    "        \n",
    "        elif strategy == 'eps_greedy':\n",
    "            print('need to work on this one')\n",
    "        \n",
    "        beliefs[trial] = beliefs_curr[-1][1]\n",
    "    \n",
    "    return y_predict, beliefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/{:}/Dropbox (HMS)/mouse_bandit/markov_full.csv'.format(username), index_col=0)\n",
    "#data = data[data['Mouse ID']=='Baby']\n",
    "data = data[data['Condition']=='80-20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(data, test_size=0.3, random_state=1) # do this to match the logreg dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict, beliefs = hmm_predict(data, 0.8, transition_prob=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for sending out prediction to test against real data\n",
    "#y_predict = np.array(y_predict)\n",
    "#np.savetxt('/Users/celiaberon/Dropbox (HMS)/mouse_bandit/model_outputs/hmm_8020_y_predict.csv', y_predict, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Greedy model'''\n",
    "\n",
    "decision = data_test['Decision'].values\n",
    "prev_decision = data_test['1_Port'].values\n",
    "\n",
    "switch = np.abs(decision-prev_decision)\n",
    "switch_predict = np.abs(y_predict-prev_decision)\n",
    "\n",
    "accuracy_greedy = np.mean(y_predict==decision)\n",
    "#accuracy=1-np.abs([y_predict[i]-decision[i] for i in range(len(beliefs))]).sum()/len(beliefs)\n",
    "print('accuracy = ', accuracy_greedy)\n",
    "\n",
    "precision=1-np.abs([switch_predict[i]-switch[i] for i in np.where(switch_predict==1)]).sum()/np.sum(switch_predict==1)\n",
    "print('precision =', precision)\n",
    "\n",
    "recall=1-np.abs([switch_predict[i]-switch[i] for i in np.where(switch==1)]).sum()/np.sum(switch==1)\n",
    "print('recall =', recall)\n",
    "\n",
    "acc_greedy_switch,acc_greedy_stay,F1=sf.score_both_and_confuse(switch_predict,switch,confusion=False,disp=True)\n",
    "\n",
    "np.random.shuffle(switch.values)\n",
    "shuffled_greedy_switch = sf.score_both_and_confuse(switch_predict,switch,confusion=False,disp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict_thompson, beliefs = hmm_predict(data_test, 0.75, transition_prob=0.035, strategy='thompson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''With Thompson sampling'''\n",
    "y_predict = [np.random.choice(2,p=[1-beliefs[i],beliefs[i]]) for i in range(len(beliefs))]\n",
    "\n",
    "decision = data_test['Decision'].values\n",
    "prev_decision = data_test['1_Port'].values\n",
    "\n",
    "switch = np.abs(decision-prev_decision)\n",
    "switch_predict = np.abs(y_predict-prev_decision)\n",
    "\n",
    "accuracy_thom = np.mean(y_predict==decision)\n",
    "#accuracy=1-np.abs([y_predict[i]-decision[i] for i in range(len(beliefs))]).sum()/len(beliefs)\n",
    "print('accuracy = ', accuracy_thom)\n",
    "\n",
    "precision=1-np.abs([switch_predict[i]-switch[i] for i in np.where(switch_predict==1)]).sum()/np.sum(switch_predict==1)\n",
    "print('precision =', precision)\n",
    "\n",
    "recall=1-np.abs([switch_predict[i]-switch[i] for i in np.where(switch==1)]).sum()/np.sum(switch==1)\n",
    "print('recall =', recall)\n",
    "\n",
    "acc_thom_switch,acc_thom_stay,F1=sf.score_both_and_confuse(switch_predict,switch,confusion=False,disp=True)\n",
    "\n",
    "np.random.shuffle(switch.values)\n",
    "shuffled_thom_switch = sf.score_both_and_confuse(switch_predict,switch,confusion=False,disp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision = data_test['Decision'].values\n",
    "prev_decision = data_test['1_Port'].values\n",
    "switch = np.abs(decision-prev_decision)\n",
    "\n",
    "acc_thom_full = []\n",
    "acc_switch_full = []\n",
    "acc_stay_full = []\n",
    "\n",
    "for n in range(0,100):\n",
    "    y_predict = [np.random.choice(2,p=[1-beliefs[i],beliefs[i]]) for i in range(len(beliefs))]\n",
    "\n",
    "    switch_predict = np.abs(y_predict-prev_decision)\n",
    "\n",
    "    accuracy_thom = np.mean(y_predict==decision)\n",
    "\n",
    "    precision=1-np.abs([switch_predict[i]-switch[i] for i in np.where(switch_predict==1)]).sum()/np.sum(switch_predict==1)\n",
    "\n",
    "    recall=1-np.abs([switch_predict[i]-switch[i] for i in np.where(switch==1)]).sum()/np.sum(switch==1)\n",
    "\n",
    "    acc_thom_switch,acc_thom_stay,F1=sf.score_both_and_confuse(switch_predict,switch,confusion=False,disp=True)\n",
    "    \n",
    "    acc_thom_full.append(accuracy_thom)\n",
    "    acc_stay_full.append(acc_thom_stay)\n",
    "    acc_switch_full.append(acc_thom_switch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(beliefs) # should be 0.5 if belief switches between ports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "barWidth = 0.2\n",
    "# The x position of bars\n",
    "r1 = np.arange(len(height_b))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "r3 = [x + barWidth for x in r2]\n",
    "\n",
    "conditions = ['full', 'stay', 'switch']\n",
    "plt.bar(r1, height_9010_greedy, width=barWidth, label='90-10')\n",
    "plt.bar(r2, height_8020_greedy, width=barWidth, label='80-20')\n",
    "plt.bar(r3, height_7030_greedy, width=barWidth, label='70-30')\n",
    "\n",
    "plt.xticks(r2, conditions)\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.ylim((0,0.95))\n",
    "plt.title('HMM Greedy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barWidth = 0.2\n",
    "# The x position of bars\n",
    "r1 = np.arange(len(height_b))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "r3 = [x + barWidth for x in r2]\n",
    "\n",
    "conditions = ['full', 'stay', 'switch']\n",
    "plt.bar(r1, height_9010_thom, width=barWidth, label='90-10')\n",
    "plt.bar(r2, height_8020_thom, width=barWidth, label='80-20')\n",
    "plt.bar(r3, height_7030_thom, width=barWidth, label='70-30')\n",
    "\n",
    "\n",
    "plt.xticks(range(len(height_b)), conditions)\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.ylim((0,0.95))\n",
    "plt.title('HMM Thompson sampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_thom_stay = acc_stay_full.copy()\n",
    "acc_thom_switch = acc_switch_full.copy()\n",
    "accuracy_thom = acc_thom_full.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_a = [accuracy_greedy, acc_greedy_stay, acc_greedy_switch]\n",
    "height_b = [np.mean(accuracy_thom), np.mean(acc_thom_stay), np.mean(acc_thom_switch)]\n",
    "\n",
    "ystd2 = [np.std(accuracy_thom), np.std(acc_thom_stay), np.std(acc_thom_switch)]\n",
    "yerr2 = [ystd2[i] / np.sqrt(100) for i in range(len(ystd2))]\n",
    "\n",
    "barWidth = 0.2\n",
    "# The x position of bars\n",
    "r1 = np.arange(len(height_b))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "r3 = [x + barWidth for x in r2]\n",
    "\n",
    "conditions = ['full', 'stay', 'switch']\n",
    "plt.bar(r1, height_a, width=barWidth, label='hmm_greedy')\n",
    "plt.bar(r2, height_b, width=barWidth, yerr=yerr2, capsize=3, label='hmm_thompson')\n",
    "\n",
    "plt.xticks([0.1, 1.1, 2.1], conditions, size=15)\n",
    "plt.ylabel('accuracy', size=15)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take just one mouse, session\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(data['Higher p port'].values[0:500])\n",
    "plt.xlabel('trial')\n",
    "plt.ylabel('hidden state')\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(beliefs[0:500])\n",
    "plt.ylabel('belief from HMM')\n",
    "\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot(data['Decision'].values[0:500])\n",
    "plt.ylabel('mouse choice')\n",
    "plt.xlabel('Trial', size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = bm.Xy_history(data)\n",
    "y_predict = pd.Series(y_predict, index=y.index)\n",
    "reward_combos_hmm, p_switch_hmm = bm.sequences_predict_switch(X,y_predict)\n",
    "reward_combos_true, p_switch_true = bm.sequences_predict_switch(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_switch_hmm-p_switch_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(left=np.arange(len(reward_combos)) ,height=p_switch_true-p_switch_hmm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
